<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>will wolf - machine-learning</title><link href="https://willwolf.io/es/" rel="alternate"/><link href="https://willwolf.io/feeds/machine-learning.atom.xml" rel="self"/><id>https://willwolf.io/es/</id><updated>2017-03-22T19:56:00-04:00</updated><subtitle>escritura sobre machine learning, crypto, la geopolítica, y la vida</subtitle><entry><title>Docker y Kaggle con Enrique y Beto</title><link href="https://willwolf.io/es/2017/03/22/docker-y-kaggle-con-enrique-y-beto/" rel="alternate"/><published>2017-03-22T19:56:00-04:00</published><updated>2017-03-22T19:56:00-04:00</updated><author><name>Will Wolf</name></author><id>tag:willwolf.io,2017-03-22:/es/2017/03/22/docker-y-kaggle-con-enrique-y-beto/</id><summary type="html">&lt;p&gt;Este post tiene como objetivo familiarizarlos con lo que es Docker, por qué y cómo usarlo para Kaggle.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Este post tiene como objetivo familiarizarlos con lo que es Docker, por qué y cómo usarlo para Kaggle. Para hacer las cosas más simples, hablaremos principalmente de Plaza Sésamo y pasteles en lugar de computadoras y datos.&lt;/p&gt;
&lt;p&gt;Una mañana de lunes, Enrique sale de debajo de su cobija rayada, pone los dos pies en el piso y abre la ventana de su cuarto. Echa un vistazo hacia la metrópoli llena de galletas y muñecos de peluche, endereza el cuello de su suéter color banana, suelta un fuerte bostezo matutino y exclama: "Hoy, voy a preparar pasteles para mi querido compañero Beto."&lt;/p&gt;
&lt;p&gt;&lt;img alt="ernie and bert" class="img-responsive" src="https://willwolf.io/es/images/ernie_and_bert.png"/&gt;&lt;/p&gt;
&lt;p&gt;Por mala suerte, Enrique nunca ha hecho pasteles antes. ¡Pero no importa! Se precipita con prisa hacia la cocina, toma un libro de cocina, organiza los ingredientes y prende su hornito Easy-Bake. "Lo pongo a prueba igual. Prepararé el mejor pastel jamás hecho por todos los muñecos de peluche. Y una vez que el resultado me complazca, haré 50 más," grita.&lt;/p&gt;
&lt;p&gt;Horas después, su trabajo termina: su pastel - tres pisos de "mini-pasteles" sabor arándano, fresa y tocino - es simplemente la mejor cosa que haya probado alguna vez en su vida. "¡Mucho mejor que cualquier cosa que ese fraude Cookie Monster haya probado jamás!" dice. Emocionado, Enrique toma una pausa en su cocina ya demasiada sucia para admirar el resultado. Piensa en Beto y se pregunta qué tan rápido se puede entregar el regalo. "Ya que he horneado el pastel perfecto, solo me toca hacer 50 más. ¿Debe ser fácil, verdad?"&lt;/p&gt;
&lt;p&gt;Enrique se da vuelta para mirar su Easy-Bake. "Pues, esa vaina solo cocina un pastel a la vez. ¡Tardaría días en hacer 50 a ese ritmo!" Aún de buen humor, corre a la panadería del pueblo para pedir prestado su horno - ese más grande que el suyo. Se lo dan en seguida y Enrique se pone a cocinar.&lt;/p&gt;
&lt;p&gt;Desafortunadamente, mientras está mezclando los ingredientes empieza a tener problemas con las herramientas de la panadería. El mezclador eléctrico se rompe. El cuchillo no corta las fresas de la manera correcta. Las tazas de medir tienen tamaños sutilmente distintos. Enrique se estresa. Pensaba que estaba al punto de terminar, pero se da cuenta de repente de que en realidad acaba de empezar. Aunque vino con la receta exacta en mano, se nota que ahora está usando herramientas diferentes en una cocina extraña, en un ambiente nuevo. "¿No puede un muñeco de peluche cocinar un solo pastel en su horno pequeño, luego traer la receta y los ingredientes a un horno más grande y ahí fabricarlos rápidamente a escala masiva? ¿Por qué tiene que ser tan complicado esto?"&lt;/p&gt;
&lt;h2&gt;Presentando Docker&lt;/h2&gt;
&lt;p&gt;Con tristeza y desesperación, Enrique camina al puerto para aclarar su mente. Allí, se encuentra con cientos de contenedores azules y blancos del tamaño de camionetas y se le ocurre una idea divertida: "¿Qué tal si cocino allí? Moveré todas mis herramientas dentro del contenedor - la tabla de cortar, el cuchillo, el mezclador, los utensilios - y escribiré la receta en el muro interior. La única cosa que faltará sería el horno, pero eso se obtiene en todas partes. Así, usando el horno en mi casa, puedo continuar horneando un pastel a la vez como siempre; por el contrario, usando el horno de la panadería puedo cocinar de capacidad aumentada. Listo. Enrique agarra el primer contenedor que ve y corre a casa para llenarlo de pastel."&lt;/p&gt;
&lt;p&gt;Después de escribir la receta en el muro interior del contenedor, Enrique se da cuenta de que lo que quiere traer a la panadería tiene que ser ligero. Si no, ¡no lo podrá llevar! Por lo tanto, en lugar de físicamente llevar sus herramientas - el cuchillo, el mezclador, etc. - simplemente escribe los nombres y números de estos productos además de instrucciones para adquirirlos por fuera. De la misma manera, en lugar de encerrar los ingredientes mismos, espera que estén disponibles en la panadería una vez que llegue. Así, cuando la receta diga "echa 3 cucharadas de azúcar del gabinete," el azúcar ya estará puesto en el gabinete mismo.&lt;/p&gt;
&lt;h2&gt;Presentando Kaggle&lt;/h2&gt;
&lt;p&gt;Hornear pasteles en Plaza Sésamo es una metáfora de construir modelos para Kaggle. Típicamente, construimos prototipos sencillos en nuestra entorno local y luego alquilamos una máquina más poderosa ubicada en alguna granja en Virginia para hacer el trabajo pesado en el sentido computacional. En las competencias de Kaggle, el problema inicial de Enrique es demasiado común: aún después de lograr conseguir un mezclador eléctrico, tazas de medir, etc. que se parecen a los suyos - esto es, aún después de instalar todas aquellas librerías en el servidor remoto que teníamos en el local - los entornos aún no eran idénticos y algunos problemas surgen en seguida. Los contenedores de Docker resuelven este problema: si podemos lograr hornear pasteles una sola vez en nuestra cocina, podemos así rehacerlos de manera determinista &lt;em&gt;n&lt;/em&gt; veces en cualquier cocina de fuera - y preferiblemente en una con un horno mucho más poderoso que el nuestro.&lt;/p&gt;
&lt;h2&gt;Con ustedes, los servidores remotos&lt;/h2&gt;
&lt;p&gt;Un servidor remoto es la panadería: es una computadora como la nuestra, pero que puede procesar datos más rápido y en cantidades más grandes. En otras palabras, es una cocina con un horno más grande.&lt;/p&gt;
&lt;h2&gt;Utensilios de cocina y los ingredientes&lt;/h2&gt;
&lt;p&gt;En lugar de incluir utensilios de cocina en nuestro contenedor simplemente pormenorizamos cuáles necesitamos y cómo adquirirlos. Para una competencia de Kaggle, esto es igual a instalar las librerías - pandas, scikit-learn, etc. - necesarias para la tarea a mano. Una vez más, no tenemos que incluir estas librerías en nuestro contenedor, sino disponer de instrucciones para dónde y cómo instalarlas. En la práctica, esto se manifiesta como un &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; en nuestro &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;&lt;code&gt;Dockerfile&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;En lugar de incluir los ingredientes en nuestro contenedor asumimos que estarán disponibles en la panadería anfitriona. Esto es un poco más complicado de lo que suena por las siguientes razones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Nuestra panadería anfitriona está a un par de cuadras de nuestra casa. Si queremos que estén disponibles los ingredientes en esa panadería, tenemos que traerlos ahí físicamente de alguna manera.&lt;/li&gt;
&lt;li&gt;Aún después de traerlos físicamente a la panadería, el cocinar que resulte dentro del contenedor estará aislado del resto de la panadería misma: la única cosa con la que se conecta exteriormente es su horno.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para una competencia de Kaggle, ¿cómo hacemos que los datos locales sean utilizables &lt;em&gt;dentro del contenedor, hospedado en un servidor remoto&lt;/em&gt;?&lt;/p&gt;
&lt;h3&gt;Los "Docker Volumes"&lt;/h3&gt;
&lt;p&gt;Los "Docker Volumes" permiten que datos sean compartidos entre una carpeta dentro de un contenedor y una carpeta en el sistema de archivo local del servidor hospedando ese contenedor. Esto es igual a lo que ocurre cuando:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Enrique trae sus ingredientes a la panadería, junto con (pero no dentro de) su contenedor.&lt;/li&gt;
&lt;li&gt;Al llegar, pone un tarro de azúcar en un cubo azul en la esquina de la sala.&lt;/li&gt;
&lt;li&gt;Se estipula que, al comenzar a hornear dentro del contenedor de la la panadería, los ingredientes se deberían compartir entre el cubo azul en la esquina de la sala y el gabinete. Así, cuando la receta diga "agarra un tarro de azúcar del gabinete," Enrique puede extender la mano hacia el gabinete dentro del contenedor y recuperar el tarro de azúcar del cubo azul en la esquina de la panadería. Recuerden: el contenedor no vino con ningún ingrediente empacado por dentro; el gabinete hubiera estado vacío por la misma razón.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Trayendo el contenedor a la panadería es igual a un sencillo &lt;code&gt;docker run&lt;/code&gt; con el servidor remoto como el &lt;code&gt;docker-machine&lt;/code&gt;. Trayendo los ingredientes a la panadería, esto es colocando datos en el sistema de archivo local del servidor remoto, es mucho menos "sexy." En el sentido más simple, es igual a usar &lt;code&gt;scp&lt;/code&gt; or &lt;code&gt;rsync&lt;/code&gt; para transferir un archivo del entorno local al servidor remoto hasta usar &lt;code&gt;curl&lt;/code&gt; para descargar un archivo directamente en el servidor remoto mismo.&lt;/p&gt;
&lt;p&gt;En la práctica, esto se ve generalmente así:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker
    --tlsverify
    --tlscacert="$HOME/.docker/machine/certs/ca.pem"
    --tlscert="$HOME/.docker/machine/certs/cert.pem"
    --tlskey="$HOME/.docker/machine/certs/key.pem" -H=tcp://12.34.56:78
run
    --rm
    -i
    -v
    /data:/data kaggle-contest build_model.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Utensilios de cocina que no se compran en la tienda&lt;/h2&gt;
&lt;p&gt;Para hacer su pastel, Enrique usó una tabla de cortar única en el mundo que Beto hizo a mano para él. ¿Cómo puede usarla en la panadería? En términos de Kaggle: ¿cómo puedo usar una librería en mi proyecto que no está disponible en un repositorio de paquetes público (una que construí yo mismo)?&lt;/p&gt;
&lt;p&gt;Para esto, no existe una "fórmula secreta." Con la tabla de cortar/librería, podemos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Incluirla en el contenedor y aguantar el peso extra.&lt;/li&gt;
&lt;li&gt;Tratarla como ingrediente, traerla a la panadería y accederla vía un "Docker Volume."&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Feliz cocinada&lt;/h2&gt;
&lt;p&gt;Trasladar tu entorno local al interior de un contenedor de Docker, y/o "Dockerizar" este entorno una vez que estés listo para usar un servidor remoto para hacer el trabajo pesado, asegurará que solo tendrás que averiguar cómo hacer el pastel una sola vez. Haz tus prototipos localmente, luego enviarlos sin estrés a la panadería para la producción de escala masiva.&lt;/p&gt;
&lt;p&gt;¡Muy buen provecho!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Recursos adicionales:&lt;/p&gt;
&lt;p&gt;Aquí dejamos dos recursos adicionales que creo útiles para aprender
sobre Docker para Kaggle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://speakerdeck.com/smly/workflow-serialization-and-docker-for-kaggle"&gt;Workflow, Serialization &amp;amp; Docker for Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2016/02/05/how-to-get-started-with-data-science-in-containers/"&gt;How to get started with data science in containers&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><category term="machine-learning"/></entry><entry><title>Gradientes de Recurrent Neural Networks y Lo Que Aprendí Derivándolos</title><link href="https://willwolf.io/es/2016/10/18/gradientes-de-recurrent-neural-networks-y-lo-que-aprendi-derivandolos/" rel="alternate"/><published>2016-10-18T14:00:00-04:00</published><updated>2016-10-18T14:00:00-04:00</updated><author><name>Will Wolf</name></author><id>tag:willwolf.io,2016-10-18:/es/2016/10/18/gradientes-de-recurrent-neural-networks-y-lo-que-aprendi-derivandolos/</id><summary type="html">&lt;p&gt;Gradientes de recurrent neural networks a mano.&lt;/p&gt;</summary><content type="html">&lt;p&gt;He pasado la mayoría de la última semana construyendo recurrent neural networks a mano. Estoy tomando el curso de &lt;a href="https://www.udacity.com/course/deep-learning--ud730"&gt;Udacity Deep Learning&lt;/a&gt;, y, llegando al contenido sobre RNN's y LSTM's, decidí construir algunos de ellos desde cero yo mismo.&lt;/p&gt;
&lt;h3&gt;¿Qué es un RNN?&lt;/h3&gt;
&lt;p&gt;Por afuera, las recurrent neural networks se diferencian del feedforward neural network típico por el hecho de que pueden ingerir &lt;em&gt;una secuencia&lt;/em&gt; de input en lugar de un sólo input de largo fijo. Concretamente, imagínense que estamos entrenando un modelo de clasificación con un puñado de tuits. Para codificar dichos tuits en el espacio vectorial, creamos un modelo de bag-of-words con un vocabulario de 3 palabras distintas. En el neural network clásico, esto implica un "input layer" con un tamaño de 3; un input podría ser &lt;span class="math"&gt;\([4, 9, 3]\)&lt;/span&gt;, o &lt;span class="math"&gt;\([1, 0, 5]\)&lt;/span&gt;, o &lt;span class="math"&gt;\([0, 0, 6]\)&lt;/span&gt;, por ejemplo. En el caso del recurrent neural network, nuestro input layer tiene el mismo tamaño de 3, pero en lugar de un sólo input, le podemos alimentar una secuencia de inputs de tamaño 3 de cualquier largo. Como ejemplo, un input podría ser &lt;span class="math"&gt;\([[1, 8, 5], [2, 2, 4]]\)&lt;/span&gt;, o &lt;span class="math"&gt;\([[6, 7, 3], [6, 2, 4], [9, 17, 5]]\)&lt;/span&gt;, o &lt;span class="math"&gt;\([[2, 3, 0], [1, 1, 7], [5, 5, 3], [8, 18, 4]]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;En su interior, las recurrent neural networks tienen un mecanismo feedforward diferente del neural network típico. Además, cada input en nuestra secuencia se procesa individual y cronológicamente: el primer input es procesado, luego el segundo, hasta procesar el último. Por fin, después de procesar todos los inputs, computamos algunos gradientes y actualizamos los parámetros (weights) de la red. Tal como en los feedforward networks, lo hacemos con backpropagation. Al contrario, ya nos toca propagarles los errores a cada parámetro en cada etapa del tiempo. Dicho de otra manera, nos toca calcular gradientes con respecto a: el estado del mundo al procesar nuestro primer input, el estado del mundo al procesar nuestro segundo input, hasta el en el que procesamos nuestro último input. Este algoritmo se llama &lt;a href="https://en.wikipedia.org/wiki/Backpropagation_through_time"&gt;Backpropagation Through Time&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Otros Recursos, Mis Frustraciones&lt;/h3&gt;
&lt;p&gt;Existen bastantes recursos para entender cómo calcular los gradientes usando el Backpropagation Through Time. En mi opinión, &lt;a href="https://www.existor.com/en/ml-rnn.html"&gt;Recurrent Neural Networks Maths&lt;/a&gt; es el más comprehensivo en un sentido matemático, mientras &lt;a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/"&gt;Recurrent Neural Networks Tutorial Part 3&lt;/a&gt; es más conciso pero igual de claro. Finalmente, está &lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086"&gt;Minimal character-level language model&lt;/a&gt; por Andrej Karpathy, acompañando su &lt;a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;blog post&lt;/a&gt; excelente sobre la teoría y el uso general de los RNN's, que al inicio me costó mucho entender.&lt;/p&gt;
&lt;p&gt;En todos los posts, pienso que los autores desafortunadamente no aclaran muy bien la línea divisoria entre la derivación de los gradientes y su implementación (eficiente) en código, o por lo menos brincan demasiado rápido del primero al segundo. Definen variables como  &lt;code&gt;dbnext&lt;/code&gt;,  &lt;code&gt;delta_t&lt;/code&gt;, y &lt;span class="math"&gt;\(e_{hi}^{2f3}\)&lt;/span&gt; sin explicar cabalmente su significado en los gradientes analíticos mismos. Como ejemplo, el primer post incluye la siguiente sección:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\frac{\partial J^{t=2}}{\partial w^{xh}_{mi}} =
e^{t=2f2}_{hi} \frac{\partial h^{t=2}_i}{\partial z^{t=2}_{hi}} \frac{\partial z^{t=2}_{hi}}{\partial w^{xh}_{mi}} +
e^{t=1f2}_{hi} \frac{\partial h^{t=1}_i} {\partial z^{t=1}_{hi}} \frac{\partial z^{t=1}_{hi}}{\partial w^{xh}_{mi}}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hasta ahora, no está hablando sino de los gradientes analíticos. A continuación, alude a la implementación-en-código que sigue.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So the thing to note is that we can delay adding in the backward propagated errors until we get further into the loop. In other words, we can initially compute the derivatives of &lt;em&gt;J&lt;/em&gt; with respect to the third unrolled network with only the first term:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\frac{\partial J^{t=3}}{\partial w^{xh}_{mi}} =
e^{t=3f3}_{hi} \frac{\partial h^{t=3}_i}{\partial z^{t=3}_{hi}} \frac{\partial z^{t=3}_{hi}}{\partial w^{xh}_{mi}}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;And then add in the other term only when we get to the second unrolled network:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\frac{\partial J^{t=2}}{\partial w^{xh}_{mi}} =
(e^{t=2f3}_{hi} + e^{t=2f2}_{hi}) \frac{\partial h^{t=2}_i}{\partial z^{t=2}_{hi}}
\frac{\partial z^{t=2}_{hi}}
{\partial w^{xh}_{mi}}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Noten las definiciones opuestas de la variable &lt;span class="math"&gt;\(\frac{\partial J^{t=2}}{\partial w^{xh}_{mi}}\)&lt;/span&gt;. Hasta donde yo sé, la segunda es, sin hacerle caso a algún posible código, categóricamente falsa. Dicho eso, creo que el autor está simplemente ofreciendo una definición alternativa para esta cantidad en cuanto a un atajo pequeño que luego tome.&lt;/p&gt;
&lt;p&gt;Sobre decir que estas ambigüedades hacen que todo se vuelva muy emocional, muy rápido. Me dejaron confundido durante dos días. Por lo tanto, el objetivo de este post es derivar los gradientes de un recurrent neural network desde cero, y clarificar enfáticamente que cualquier atajo de implementación que siga no es nada más que ese mismo, y que no tiene nada que ver con la definición analítica del gradiente correspondiente. En otras palabras, si puedes derivar los gradientes, has ganado. Escribe un test unitario, implementa dichos gradientes de la manera más cruda posible, velo pasar, y enseguida te darás cuenta de que puedes hacer tu código mucho más eficiente con muy poco esfuerzo. A esa altura, todos los "atajos" que tomen los autores ya mencionados te van a parecer absolutamente obvios.&lt;/p&gt;
&lt;h3&gt;Backpropagation Through Time&lt;/h3&gt;
&lt;p&gt;En el caso más simple, asumamos que nuestra red tiene 3 capas, y tan sólo 3 parámetros para optimizar: &lt;span class="math"&gt;\(\mathbf{W^{xh}}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathbf{W^{hh}}\)&lt;/span&gt; y &lt;span class="math"&gt;\(\mathbf{W^{hy}}\)&lt;/span&gt;. Las ecuaciones principales son las siguientes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathbf{z_t} = \mathbf{W^{xh}}\mathbf{x} + \mathbf{W^{hh}}\mathbf{h_{t-1}}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathbf{h_t} = \tanh(\mathbf{z_t})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathbf{y_t} = \mathbf{W^{hy}}\mathbf{h_t}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathbf{p_t} = \text{softmax}(\mathbf{y_t})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\mathbf{J_t} = \text{crossentropy}(\mathbf{p_t}, \mathbf{\text{labels}})\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;He escrito "softmax" y "cross-entropy" por cuestiones de claridad: antes de emprender lo siguiente, es crucial entender lo que hacen y cómo calcular sus gradientes a mano.&lt;/p&gt;
&lt;p&gt;Antes de avanzar, damos la definición de una derivada parcial misma:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Una derivada parcial, &lt;span class="math"&gt;\(\frac{\partial y}{\partial x}\)&lt;/span&gt; por ejemplo, nos dice cuánto crece &lt;span class="math"&gt;\(y\)&lt;/span&gt; a consecuencia de un cambio en &lt;span class="math"&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nuestro costo &lt;span class="math"&gt;\(\mathbf{J_t}\)&lt;/span&gt; es el costo &lt;em&gt;total&lt;/em&gt; (no el costo promedio) de una cierta secuencia de inputs. Por eso, un cambio de una unidad en &lt;span class="math"&gt;\(\mathbf{W^{hy}}\)&lt;/span&gt; impacta a &lt;span class="math"&gt;\(\mathbf{J_1}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\mathbf{J_2}\)&lt;/span&gt; y &lt;span class="math"&gt;\(\mathbf{J_3}\)&lt;/span&gt; por separado. En consecuencia, nuestro gradiente equivale a la suma de los gradientes respectivos en cada etapa de tiempo &lt;span class="math"&gt;\(t\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$
\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hy}}} =
\sum\limits_t \frac{\partial \mathbf{J_t}}{\partial
\mathbf{W^{hy}}} = \frac{\partial \mathbf{J_3}}{\partial
\mathbf{W^{hy}}} + \frac{\partial \mathbf{J_2}}{\partial
\mathbf{W^{hy}}} + \frac{\partial \mathbf{J_1}}{\partial
\mathbf{W^{hy}}}\\
\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hh}}} =
\sum\limits_t \frac{\partial \mathbf{J_t}}{\partial
\mathbf{W^{hh}}} = \frac{\partial \mathbf{J_3}}{\partial
\mathbf{W^{hh}}} + \frac{\partial \mathbf{J_2}}{\partial
\mathbf{W^{hh}}} + \frac{\partial \mathbf{J_1}}{\partial
\mathbf{W^{hh}}}\\
\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{xh}}} =
\sum\limits_t \frac{\partial \mathbf{J_t}}{\partial
\mathbf{W^{xh}}} = \frac{\partial \mathbf{J_3}}{\partial
\mathbf{W^{xh}}} + \frac{\partial \mathbf{J_2}}{\partial
\mathbf{W^{xh}}} + \frac{\partial \mathbf{J_1}}{\partial
\mathbf{W^{xh}}}$$&lt;/div&gt;
&lt;p&gt;Tomémoslo pasa a paso.&lt;/p&gt;
&lt;h3&gt;Derivadas Algebraicas&lt;/h3&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hy}}}\)&lt;/span&gt;:&lt;/h4&gt;
&lt;p&gt;Empezando con&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{hy}}}\)&lt;/span&gt;, notamos que un cambio en &lt;span class="math"&gt;\(\mathbf{W^{hy}}\)&lt;/span&gt; impacta a &lt;span class="math"&gt;\(\mathbf{J_3}\)&lt;/span&gt; sólo cuando &lt;span class="math"&gt;\(t=3\)&lt;/span&gt;, y no a ninguna otra cantidad. Sigue que:&lt;/p&gt;
&lt;div class="math"&gt;$$
\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{hy}}} =
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}\frac{\partial \mathbf{y_3}}{\partial \mathbf{W^{hy}}}\\
\frac{\partial \mathbf{J_2}}{\partial \mathbf{W^{hy}}} =
\frac{\partial \mathbf{J_2}}{\partial \mathbf{p_2}}
\frac{\partial \mathbf{p_2}}{\partial \mathbf{y_2}}\frac{\partial \mathbf{y_2}}{\partial \mathbf{W^{hy}}}\\
\frac{\partial \mathbf{J_1}}{\partial \mathbf{W^{hy}}} =
\frac{\partial \mathbf{J_1}}{\partial \mathbf{p_1}}
\frac{\partial \mathbf{p_1}}{\partial \mathbf{y_1}}\frac{\partial \mathbf{y_1}}{\partial \mathbf{W^{hy}}}
$$&lt;/div&gt;
&lt;h4&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hh}}}\)&lt;/span&gt;:&lt;/h4&gt;
&lt;p&gt;Empezando con &lt;span class="math"&gt;\(\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{hh}}}\)&lt;/span&gt;, un cambio en &lt;span class="math"&gt;\(\mathbf{W^{hh}}\)&lt;/span&gt; impacta a nuestro costo en &lt;em&gt;3 momentos distintos:&lt;/em&gt; por primera vez al calcular el valor de &lt;span class="math"&gt;\(\mathbf{h_1}\)&lt;/span&gt;; por segunda vez al calcular el valor de &lt;span class="math"&gt;\(\mathbf{h_2}\)&lt;/span&gt;, que está condicionado a &lt;span class="math"&gt;\(\mathbf{h_1}\)&lt;/span&gt;; por tercera vez al calcular &lt;span class="math"&gt;\(\mathbf{h_3}\)&lt;/span&gt;, que está condicionado a &lt;span class="math"&gt;\(\mathbf{h_2}\)&lt;/span&gt;, que está condicionado a &lt;span class="math"&gt;\(\mathbf{h_1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;En términos más generales, un cambio en &lt;span class="math"&gt;\(\mathbf{W^{hh}}\)&lt;/span&gt; impacta al costo &lt;span class="math"&gt;\(\mathbf{J_t}\)&lt;/span&gt; en &lt;span class="math"&gt;\(t\)&lt;/span&gt; momentos distintos. Sigue que:&lt;/p&gt;
&lt;div class="math"&gt;$$
\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hh}}} =
\sum\limits_{k=0}^{t} \frac{\partial \mathbf{J_t}}{\partial
\mathbf{h_t}} \frac{\partial \mathbf{h_t}}{\partial
\mathbf{h_k}} \frac{\partial \mathbf{h_k}}{\partial
\mathbf{z_k}} \frac{\partial \mathbf{z_k}}{\partial
\mathbf{W^{hh}}}
$$&lt;/div&gt;
&lt;p&gt;Con esta definición, calculamos nuestras gradientes como:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{hh}}} &amp;amp;=
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{W^{hh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{W^{hh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{hh}}}\\
\end{align*}
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_2}}{\partial \mathbf{W^{hh}}} &amp;amp;=
\frac{\partial \mathbf{J_2}}{\partial \mathbf{p_2}}
\frac{\partial \mathbf{p_2}}{\partial \mathbf{y_2}}
\frac{\partial \mathbf{y_2}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{W^{hh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_2}}{\partial \mathbf{p_2}}
\frac{\partial \mathbf{p_2}}{\partial \mathbf{y_2}}
\frac{\partial \mathbf{y_2}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{hh}}}
\end{align*}
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_1}}{\partial \mathbf{W^{hh}}} &amp;amp;=
\frac{\partial \mathbf{J_1}}{\partial \mathbf{p_1}}
\frac{\partial \mathbf{p_1}}{\partial \mathbf{y_1}}
\frac{\partial \mathbf{y_1}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{hh}}}
\end{align*}
$$&lt;/div&gt;
&lt;h4&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{xh}}}\)&lt;/span&gt;:&lt;/h4&gt;
&lt;p&gt;Análogamente:&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{xh}}} =
\sum\limits_{k=0}^{t} \frac{\partial \mathbf{J_t}}{\partial
\mathbf{h_t}} \frac{\partial \mathbf{h_t}}{\partial
\mathbf{h_k}} \frac{\partial \mathbf{h_k}}{\partial
\mathbf{z_k}} \frac{\partial \mathbf{z_k}}{\partial
\mathbf{W^{xh}}}$$&lt;/div&gt;
&lt;p&gt;Así que:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{xh}}} &amp;amp;=
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{W^{xh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{W^{xh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_3}}{\partial \mathbf{p_3}}
\frac{\partial \mathbf{p_3}}{\partial \mathbf{y_3}}
\frac{\partial \mathbf{y_3}}{\partial \mathbf{h_3}}
\frac{\partial \mathbf{h_3}}{\partial \mathbf{z_3}}
\frac{\partial \mathbf{z_3}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{xh}}}
\end{align*}
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_2}}{\partial \mathbf{W^{xh}}} &amp;amp;=
\frac{\partial \mathbf{J_2}}{\partial \mathbf{p_2}}
\frac{\partial \mathbf{p_2}}{\partial \mathbf{y_2}}
\frac{\partial \mathbf{y_2}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{W^{xh}}}\\ &amp;amp;+
\frac{\partial \mathbf{J_2}}{\partial \mathbf{p_2}}
\frac{\partial \mathbf{p_2}}{\partial \mathbf{y_2}}
\frac{\partial \mathbf{y_2}}{\partial \mathbf{h_2}}
\frac{\partial \mathbf{h_2}}{\partial \mathbf{z_2}}
\frac{\partial \mathbf{z_2}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{xh}}}
\end{align*}
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\begin{align*}
\frac{\partial \mathbf{J_1}}{\partial \mathbf{W^{xh}}} &amp;amp;=
\frac{\partial \mathbf{J_1}}{\partial \mathbf{p_1}}
\frac{\partial \mathbf{p_1}}{\partial \mathbf{y_1}}
\frac{\partial \mathbf{y_1}}{\partial \mathbf{h_1}}
\frac{\partial \mathbf{h_1}}{\partial \mathbf{z_1}}
\frac{\partial \mathbf{z_1}}{\partial \mathbf{W^{xh}}}
\end{align*}
$$&lt;/div&gt;
&lt;h3&gt;Derivadas Analíticas&lt;/h3&gt;
&lt;p&gt;Finalmente, insertamos las derivadas parciales individuales para llegar a los gradientes finales con lo siguiente en mano:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial y} = \mathbf{p_t} - \mathbf{\text{labels}_t}\)&lt;/span&gt;, where &lt;span class="math"&gt;\(\mathbf{\text{labels}_t}\)&lt;/span&gt; is a one-hot vector of the correct answer at a given time-step &lt;span class="math"&gt;\(t\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial \mathbf{W^{hy}}} = (\mathbf{p_t} - \mathbf{\text{labels}_t})\mathbf{h_t}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{J_t}}{\partial \mathbf{h_t}} = (\mathbf{p_t} - \mathbf{\text{labels}_t})\mathbf{W^{hy}}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{h_t}}{\partial \mathbf{z_t}} = 1 - \tanh^2(\mathbf{z_t}) = 1 - \mathbf{h_t}^2\)&lt;/span&gt;, as &lt;span class="math"&gt;\(\mathbf{h_t} = \tanh(\mathbf{z_t})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{z_t}}{\mathbf{h_{t-1}}} = \mathbf{W^{hh}}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{\partial \mathbf{z_t}}{\partial \mathbf{W^{xh}}} = \mathbf{x_t}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(\frac{z_t}{\partial \mathbf{W^{hh}}} = \mathbf{h_{t-1}}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A esta altura, has terminado: has calculado tus gradientes, y entiendes bien el algoritmo de Backpropagation Through Time. De aquí en adelante, lo único que queda es escribir algunos for-loops.&lt;/p&gt;
&lt;h3&gt;Atajos de Implementación&lt;/h3&gt;
&lt;p&gt;Al calcular le gradiente de, por ejemplo, &lt;span class="math"&gt;\(\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{xh}}}\)&lt;/span&gt;, se nota de inmediato que necesitamos acceso a los labels de &lt;span class="math"&gt;\(t=3\)&lt;/span&gt;, &lt;span class="math"&gt;\(t=2\)&lt;/span&gt; y &lt;span class="math"&gt;\(t=1\)&lt;/span&gt;. Para &lt;span class="math"&gt;\(\frac{\partial \mathbf{J_2}}{\partial \mathbf{W^{xh}}}\)&lt;/span&gt;, necesitamos acceso a los labels de &lt;span class="math"&gt;\(t=2\)&lt;/span&gt; y &lt;span class="math"&gt;\(t=1\)&lt;/span&gt;. Por fin, para &lt;span class="math"&gt;\(\frac{\partial \mathbf{J_1}}{\partial \mathbf{W^{xh}}}\)&lt;/span&gt;, necesitamos los labels de &lt;span class="math"&gt;\(t=1\)&lt;/span&gt;. Naturalmente, nos preguntamos cómo podemos hacer este proceso más eficiente: por ejemplo, para calcular &lt;span class="math"&gt;\(\frac{\partial \mathbf{J_3}}{\partial \mathbf{W^{xh}}}\)&lt;/span&gt;, ¿qué tal sólo calcular las partes de &lt;span class="math"&gt;\(t=3\)&lt;/span&gt; a &lt;span class="math"&gt;\(t=3\)&lt;/span&gt;, y agregarle el resto en los pasos del tiempo que siguen? En lugar de profundizar, te los dejo a ustedes: esta parte es trivial en el fondo, un buen ejercicio para el practicante, y al acabar vas a descubrir de repente que tu código se parece bastante al de los recursos arriba.&lt;/p&gt;
&lt;h3&gt;Aprendizajes del Proceso&lt;/h3&gt;
&lt;p&gt;Mediante este proceso, aprendí varias cosas claves:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Al querer implementar un neural network desde cero, deriva las gradientes a mano al inicio. &lt;em&gt;Esto hace que todo salga mucho más fácil.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Usa más el lápiz y papel antes de siquiera escribir una sola linea de código. No dan miedo y tienen absolutamente su función.&lt;/li&gt;
&lt;li&gt;El "chain rule" queda simple y claro. Si una derivada parece estar fuera de esta dificultad general, es probable que haya otro detalle importante que te falta reconocer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Felices RNN's.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Referencias claves para este artículo se nombran:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/"&gt;Recurrent Neural Networks Tutorial Part 2 Implementing A Rnn With Python Numpy And Theano&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/"&gt;Recurrent Neural Networks Tutorial Part 3 Backpropagation Through Time And Vanishing Gradients&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gist.github.com/karpathy/d4dee566867f8291f086"&gt;Minimal character-level language model with a Vanilla Recurrent Neural Network, in Python/numpy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.existor.com/en/ml-rnn.html"&gt;Machine Learning - Recurrent Neural Networks Maths&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="machine-learning"/></entry><entry><title>Simulación Estadística del Plebiscito Colombiano: ¿Realmente Ganaron Los del "No?"</title><link href="https://willwolf.io/es/2016/10/12/simulating-the-colombian-peace-vote-did-the-no-really-win-2/" rel="alternate"/><published>2016-10-12T11:53:00-04:00</published><updated>2016-10-12T11:53:00-04:00</updated><author><name>Will Wolf</name></author><id>tag:willwolf.io,2016-10-12:/es/2016/10/12/simulating-the-colombian-peace-vote-did-the-no-really-win-2/</id><summary type="html">&lt;p&gt;Una simulación estadística del &lt;a href="https://en.wikipedia.org/wiki/Colombian_peace_agreement_referendum,_2016"&gt;plebiscito colombiano de 2016&lt;/a&gt;.&lt;/p&gt;</summary><content type="html">&lt;p&gt;El 2 de octubre del 2016, observé con terror como los colombianos votaron por el "No" en su plebiscito nacional para decretar el recién firmado acuerdo de paz. En la siguiente semana, medité sobre el resultado y las cosas que hubieran sucedido: la gran campaña de desinformación, las payasadas de Uribe y lo súper bueno que realmente parecía el &lt;a href="https://www.youtube.com/playlist?list=PLa28R7QEiMblKeZ_OlZ_XfjjxjfeIhpuL"&gt;acuerdo&lt;/a&gt; mismo. Hace dos días, me topé por casualidad con este &lt;a href="https://theconversation.com/colombia-did-not-vote-no-in-its-peace-referendum-what-the-statistics-reveal-66471"&gt;post&lt;/a&gt;, que nos pide recordar que el margen escaso con el que ganó el "No" - 6,431,376 vs. 6,377,482 - no es particularmente convincente, ni, en realidad, tan decisivo frente al error humano.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;And as with all manual voting systems, one cannot rule out at least some degree of misclassification of papers on some scale, no matter how small. We know of no evidence of cheating, and Colombia is to be lauded for the seriousness of its referendum process, but the distinction between intentional and unintentional misclassification by individual counters can occasionally become blurred in practice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;En otras palabras, fueron seres humanos - seres humanos agotados - contando los votos a mano.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The technology of tired humans sorting pieces of paper into four stacks is, at best, crude. As a large research literature has made clear, we can reasonably assume that even well-rested people would have made mistakes with between 0.5% and 1% of the ballots. On this estimate, about 65,000-130,000 votes would have been unintentionally misclassified. It means the number of innocent counting errors could easily be substantially larger than the 53,894 yes-no difference.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;¿Sería posible que la mayoría quería el "Sí" y sin embargo perdió igual?&lt;/p&gt;
&lt;p&gt;Para investigarlo, podemos formular el proceso del voto como un sencillo proceso estadístico y preguntarse: "Si repitiéramos el plebiscito muchas más veces, ¿con qué frecuencia ganaría el 'Sí' de verdad?"&lt;/p&gt;
&lt;p&gt;Si queremos, podemos analizar el problema desde un lado analítico, que es decir resolverlo a mano con un lápiz y papel. Esto se pone complicado rápido. Más bien, nos negamos de hacerle tanto caso a la teoría y corremos una simulación básica en su lugar; &lt;a href="https://speakerdeck.com/jakevdp/statistics-for-hackers"&gt;"si sabes escribir un for-loop, puedes tú hacer los estadísticos."&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Formulemos el problem así:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(V_t=13,066,047\)&lt;/span&gt; votantes llegan a votar.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(p_{\text{yes}}\%\)&lt;/span&gt; de los votantes tienen la intención de votar por el "Sí", mientras el resto &lt;span class="math"&gt;\((1-p_{\text{yes}})\%\)&lt;/span&gt; tienen la intención de votar por el "No."&lt;/li&gt;
&lt;li&gt;Cada persona invalida su voto (por dejarlo no marcado o nulo) con una probabilidad de &lt;span class="math"&gt;\(p_{\text{invalid}}\%\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Cada voto válido se pone en la urna incorrecta con una probabilidad de &lt;span class="math"&gt;\(p_{\text{misclassification}}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;El voto mayoritario gana.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;YES_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;6377482&lt;/span&gt;
&lt;span class="n"&gt;NO_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;6431376&lt;/span&gt;
&lt;span class="n"&gt;UNMARKED_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;86243&lt;/span&gt;
&lt;span class="n"&gt;NULL_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;170946&lt;/span&gt;

&lt;span class="n"&gt;TOTAL_VOTES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;YES_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;NO_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;UNMARKED_BALLOTS&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;NULL_BALLOTS&lt;/span&gt;
&lt;span class="n"&gt;P_INVALID&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;.02&lt;/span&gt;
&lt;span class="n"&gt;P_MISCLASSIFICATION&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;.01&lt;/span&gt;
&lt;span class="n"&gt;N_TRIALS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;En cada prueba, asumimos una proporción verdadera y subyacente &lt;span class="math"&gt;\(p_{\text{yes}}\%\)&lt;/span&gt; de gente que vota por el "Sí." Por ejemplo, si le damos .48 al &lt;span class="math"&gt;\(p_{\text{yes}}\)&lt;/span&gt;, tendremos &lt;span class="math"&gt;\(V_t * p_{\text{yes}}\)&lt;/span&gt; individuos con la intención de votar por el "Sí," y los demás &lt;span class="math"&gt;\(V_t * (1-p_{\text{yes}})\)&lt;/span&gt; por el "No." Asumimos que estos valores son estáticos: no son generados por un proceso random.&lt;/p&gt;
&lt;p&gt;A continuación, cada person entrega un voto inválido con probabilidad &lt;span class="math"&gt;\(p_{\text{invalid}}\)&lt;/span&gt;, que modelamos como una Binomial random variable. Los votos válidos que quedan se ponen en la urna equivocada, también modelado con un proceso Binomial. Por fin, el número de votos por el "Sí" y por el "No" se cuentan, y el porcentaje de los que pertenecen al "Sí" se entrega.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;simulate_vote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probability_yes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;yes_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TOTAL_VOTES&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;probability_yes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;no_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TOTAL_VOTES&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;yes_votes&lt;/span&gt;

    &lt;span class="n"&gt;yes_votes_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N_TRIALS&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;yes_votes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;no_votes_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N_TRIALS&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;no_votes&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;invalid_ballots_yes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;yes_votes_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;P_INVALID&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;invalid_ballots_no&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;no_votes_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;P_INVALID&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;valid_yes_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yes_votes&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;invalid_ballots_yes&lt;/span&gt;
    &lt;span class="n"&gt;valid_no_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;no_votes&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;invalid_ballots_no&lt;/span&gt;

    &lt;span class="n"&gt;yes_votes_from_yes_voters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;valid_yes_votes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;P_MISCLASSIFICATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;no_votes_from_yes_voters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_yes_votes&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;yes_votes_from_yes_voters&lt;/span&gt;

    &lt;span class="n"&gt;no_votes_from_no_voters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;binomial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;valid_no_votes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;P_MISCLASSIFICATION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;yes_votes_from_no_voters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_no_votes&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;no_votes_from_no_voters&lt;/span&gt;

    &lt;span class="n"&gt;tallied_yes_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yes_votes_from_yes_voters&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;yes_votes_from_no_voters&lt;/span&gt;
    &lt;span class="n"&gt;tallied_no_votes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;no_votes_from_no_voters&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;no_votes_from_yes_voters&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tallied_yes_votes&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tallied_yes_votes&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;tallied_no_votes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Intentémoslo para valores diferentes de &lt;span class="math"&gt;\(p_{\text{yes}}\)&lt;/span&gt;. Para empezar, si el porcentaje verdadero y subyacente de los que querían el "Sí" fuera 51%, ¿con qué frecuencia ganaría el "No?"&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;

&lt;span class="n"&gt;percentage_of_tallied_votes_that_were_yes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;simulate_vote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;.51&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;percentage_of_tallied_votes_that_were_yes&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;Out&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
&lt;span class="mf"&gt;0.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Un resultado lógico. Dadas nuestras suposiciones, si 51% de los colombianos tuviera la intención de votar por el "Sí," el "No" hubiera ganado igual en 0 de 100,000 pruebas. Pues, la pregunta es la siguiente: ¿cuánto nos podemos acercar a la linea divisoria antes de empezar a ver resultados que no son representativos?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1e-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-7&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;probability_yes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;.5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;
    &lt;span class="n"&gt;percentage_of_tallied_votes_that_were_yes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;simulate_vote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probability_yes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;proportion_of_trials_won_by_no&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;percentage_of_tallied_votes_that_were_yes&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"p_yes: &lt;/span&gt;&lt;span class="si"&gt;{:1.6f}&lt;/span&gt;&lt;span class="s2"&gt;% | no_win_percentage: &lt;/span&gt;&lt;span class="si"&gt;{:1.3f}&lt;/span&gt;&lt;span class="s2"&gt;%"&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;probability_yes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;proportion_of_trials_won_by_no&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;60.000000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;51.000000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.100000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.010000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.191&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.001000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;38.688&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.000100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;48.791&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;span class="n"&gt;p_yes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.000010&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;no_win_percentage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;50.063&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;La primera frustración llega cuando &lt;span class="math"&gt;\(p_{\text{yes}} = .5001\)&lt;/span&gt;: si &lt;span class="math"&gt;\(V_t * p_{\text{yes}} = 13,066,047 * .5001 \approx 6,534,330\)&lt;/span&gt; votantes quisieran el "Sí" vs. &lt;span class="math"&gt;\(\approx 6,531,716\)&lt;/span&gt; el "No," el "No" hubiera ganado igual el &lt;span class="math"&gt;\(0.191\%\)&lt;/span&gt; del tiempo. Otra vez, este resultado cuenta con el error humano: tanto por parte del votante en producir un voto inválido, como el del personal en introducir por accidente dicho voto en la urna equivocada.&lt;/p&gt;
&lt;p&gt;Mientras continuamos con la lista, los resultados se tornan más variables. Al &lt;span class="math"&gt;\(p_{\text{yes}} = .50001\)&lt;/span&gt;, se puede esperar que gane el "Sí" en tan sólo el &lt;span class="math"&gt;\(1 - .38688 = 61.312\%\)&lt;/span&gt; del tiempo. Por fin, al &lt;span class="math"&gt;\(p_{\text{yes}} = .5000001\)&lt;/span&gt; (que significa, tengan en cuenta, que existe una diferencia de personas que tenían la intención de votar por el "Sí" vs. por el "No" de tan sólo &lt;span class="math"&gt;\(13,066,047 * (p_{\text{yes}} - (1 - p_{\text{yes}})) \approx 3\)&lt;/span&gt;), el "No" aún hubiera ganado de veras en la &lt;em&gt;mayoría&lt;/em&gt; de las pruebas hipotéticas. En ese caso, no estamos haciendo nada más que lanzar monedas.&lt;/p&gt;
&lt;p&gt;En resumen, como dicen los autores del post mencionado, sería estadísticamente irresponsable aducir una victoria definitiva para el "No." De otra manera, el margen verdadera y subyacente parece súper escaso de verdad: al fin del día, quizás un voto mayoritario no sea la mejor forma para resolver esta clase de problemas.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Código:&lt;/p&gt;
&lt;p&gt;Pueden encontrar el &lt;a href="http://nbviewer.jupyter.org/github/cavaunpeu/colombia-vote-simulation/blob/master/colombia-vote-simulation.ipynb"&gt;notebook&lt;/a&gt; y &lt;a href="https://github.com/cavaunpeu/colombia-vote-simulation"&gt;repo&lt;/a&gt; para este análisis aquí. &lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Referencias claves incluyen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://theconversation.com/colombia-did-not-vote-no-in-its-peace-referendum-what-the-statistics-reveal-66471"&gt;Colombia did not vote ‘no’ in its peace referendum – what the statistics reveal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://andrewgelman.com/2016/10/04/did-colombia-really-vote-no-in-that-peace-referendum/"&gt;Did Colombia really vote no in that peace referendum?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://plebiscito.registraduria.gov.co/99PL/DPLZZZZZZZZZZZZZZZZZ_L1.htm"&gt;Plebiscito Site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;Gracias a Daniela Fleishman por su edición.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="machine-learning"/></entry></feed>