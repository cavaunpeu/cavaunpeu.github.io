<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>will wolf</title>
	<meta name="description" content="writings on machine learning, crypto, geopolitics, life">
	<meta name="author" content="Will Wolf">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Favicon -->
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
	<link rel="icon" href="/favicon.ico" type="image/x-icon">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="https://willwolf.io/theme/html5.js"></script>
		<![endif]-->

	<!-- Atom Feed -->

	<!-- Twitter Cards -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@willwolf_">
  <meta name="twitter:creator" content="@willwolf_">
  <meta name="twitter:domain" content="https://willwolf.io">
    <meta property="twitter:title" content="Minimizing the Negative Log-Likelihood, in English"/>
    <meta property="twitter:description" content="Statistical underpinnings of the machine learning models we know and love. A walk through random variables, entropy, exponential family distributions, generalized linear models, maximum likelihood estimation, cross entropy, KL-divergence, maximum a posteriori estimation and going &#34;fully Bayesian.&#34;"/>
    <meta property="twitter:image" content="https://willwolf.io/images/bottleneck.png"/>

	<!-- CSS -->
	<link href="https://willwolf.io/theme/css/ipython.css?v={12345}" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
	<link href='https://fonts.googleapis.com/css?family=Berkshire Swash' rel='stylesheet' type='text/css'>
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootswatch/3.3.7/simplex/bootstrap.min.css" rel="stylesheet">
	<link href="https://willwolf.io/theme/css/local.css?v={12345}" rel="stylesheet">
	<link href="https://willwolf.io/theme/css/pygments.css?v={12345}" rel="stylesheet">
	<link href="https://willwolf.io/theme/css/main.css?v={12345}" rel="stylesheet">
</head><body>
<div class="container">
<div class="page-header">
  <nav class="navbar navbar-default">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <h1><a id="site-title" href="https://willwolf.io/">will wolf</a></h1>
            <h4 id="site-subtitle-with-links">writings on <a id="sitesubtitle-machine-learning" href="/machine-learning">machine learning</a>, <a id="sitesubtitle-crypto" href="/crypto">crypto</a>, <a id="sitesubtitle-geopolitics" href="/geopolitics">geopolitics</a>, <a id="sitesubtitle-life" href="/life">life</a></h4>
      </div>
      <div class="collapse navbar-collapse" id="myNavbar">
        <ul class="nav navbar-nav navbar-right">
              <li><a href="https://willwolf.io/about/" title="About">About</a></li>
              <li><a href="https://willwolf.io/consulting/" title="Consulting"></span> Consulting</a></li>
              <li><a href="https://willwolf.io/books/" title="Books">Books</a></li>
          <li>
            <button id="subscribeButton">
              <a href="https://willwolf.io/subscribe/" title="Get new posts by email">Subscribe</a>
            </button>
          </li>
        </ul>
      </div>
    </div>
  </nav>
</div>	<div class="row">
		<div class="col-md-10 col-md-offset-1">
<div class="article" itemscope itemtype="http://schema.org/BlogPosting">
	<div class="text-center article-header">
		<h1 itemprop="name headline" class="article-title">Minimizing the Negative Log-Likelihood, in English</h1>
		<span itemprop="author" itemscope itemtype="http://schema.org/Person">
			<h4 itemprop="name">Will Wolf</h4>
		</span>
		<time datetime="2017-05-18T12:24:00-04:00" itemprop="datePublished">May 18, 2017</time>
	</div>
	<div itemprop="articleBody" class="article-body"><p>Roughly speaking, my machine learning journey began on <a href="http://kaggle.com">Kaggle</a>. "There's data, a model (i.e. estimator) and a loss function to optimize," I learned. "Regression models predict continuous-valued real numbers; classification models predict 'red,' 'green,' 'blue.' Typically, the former employs the mean squared error or mean absolute error; the latter, the cross-entropy loss. Stochastic gradient descent updates the model's parameters to drive these losses down." Furthermore, to fit these models, just <code>import sklearn</code>.</p>
<p>A dexterity with the above is often sufficient for—at least from a technical stance—both employment and impact as a data scientist. In industry, commonplace prediction and inference problems—binary churn, credit scoring, product recommendation and A/B testing, for example—are easily matched with an off-the-shelf algorithm plus proficient data scientist for a measurable boost to the company's bottom line. In a vacuum I think this is fine: the winning driver does not <em>need</em> to know how to build the car. Surely, I've been this person before.</p>
<p>Once fluid with "scikit-learn fit and predict," I turned to statistics. I was always aware that the two were related, yet figured them ultimately parallel sub-fields of my job. With the former, I build classification models; with the latter, I infer signup counts with the Poisson distribution and MCMC—right?</p>
<p>Before long, I dove deeper into machine learning—reading textbooks, papers and source code and writing this blog. Therein, I began to come across <em>terms I didn't understand used to describe the things that I did.</em> "I understand what the categorical cross-entropy loss is, what it does and how it's defined," for example: <em><strong>"why are you calling it the negative log-likelihood?"</strong></em></p>
<p>Marginally wiser, I now know two truths about the above:</p>
<ol>
<li>Techniques we anoint as "machine learning"—classification and regression models, notably—have their underpinnings almost entirely in statistics. For this reason, terminology often flows between the two.</li>
<li>None of this stuff is new.</li>
</ol>
<p>The goal of this post is to take three models we know, love, and know how to use and explain what's really going on underneath the hood. I will assume the reader is familiar with concepts in both machine learning and statistics, and comes in search of a deeper understanding of the connections therein. There will be math—but only as much as necessary. Most of the derivations can be skipped without consequence.</p>
<p>When deploying a predictive model in a production setting, it is generally in our best interest to <code>import sklearn</code>, i.e. use a model that someone else has built. This is something we already know how to do. As such, this post will start and end here: your head is currently above water; we're going to dive into the pool, touch the bottom, then work our way back to the surface. Lemmas will be written in <em><strong>bold</strong></em>.</p>
<p><img alt="bottom of pool" class="img-responsive" src="https://previews.123rf.com/images/cookelma/cookelma1603/cookelma160300003/53105871-man-sitting-on-the-bottom-of-the-swimming-pool-under-water.jpg"/></p>
<p>First, let's meet our three protagonists. We'll define them in <a href="https://keras.io/">Keras</a> for the illustrative purpose of a unified and idiomatic API.</p>
<h2><a href="http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/">Linear regression</a> with mean squared error</h2>
<div class="highlight"><pre><span></span><code><span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span><span class="p">)</span>
</code></pre></div>
<h2><a href="http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/">Logistic regression</a> with binary cross-entropy loss</h2>
<div class="highlight"><pre><span></span><code><span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">)</span>
</code></pre></div>
<h2><a href="http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/">Softmax regression</a> with categorical cross-entropy loss</h2>
<div class="highlight"><pre><span></span><code><span class="nb">input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">)</span>
</code></pre></div>
<p>Next, we'll select four components key to each: its response variable, functional form, loss function and loss function plus regularization term. For each model, we'll describe the statistical underpinnings of each component—the steps on the ladder towards the surface of the pool.</p>
<p>Before diving in, we'll need to define a few important concepts.</p>
<h2>Random variable</h2>
<p>I define a random variable as "a thing that can take on a bunch of different values."</p>
<ul>
<li>"The tenure of despotic rulers in Central Africa" is a random variable. It could take on values of 25.73 years, 14.12 years, 8.99 years, ad infinitum; it could not take on values of 1.12 million years, nor -5 years.</li>
<li>"The height of the next person to leave the supermarket" is a random variable.</li>
<li>"The color of shirt I wear on Mondays" is a random variable. (Incidentally, this one only has ~3 distinct values.)</li>
</ul>
<h2>Probability distribution</h2>
<p>A probability distribution is a lookup table for the likelihood of observing each unique value of a random variable. Assuming a given variable can take on values in <span class="math">\(\{\text{rain, snow, sleet, hail}\}\)</span>, the following is a valid probability distribution:</p>
<div class="highlight"><pre><span></span><code><span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'rain'</span><span class="p">:</span> <span class="mf">.14</span><span class="p">,</span> <span class="s1">'snow'</span><span class="p">:</span> <span class="mf">.37</span><span class="p">,</span> <span class="s1">'sleet'</span><span class="p">:</span> <span class="mf">.03</span><span class="p">,</span> <span class="s1">'hail'</span><span class="p">:</span> <span class="mf">.46</span><span class="p">}</span>
</code></pre></div>
<p>Trivially, these values must sum to 1.</p>
<ul>
<li>A <em>probability mass function</em> is a probability distribution for a discrete-valued random variable.</li>
<li>A <em>probability density function</em> <em><strong>gives</strong></em> a probability distribution for a continuous-valued random variable.<ul>
<li><em>Gives</em>, because this function itself is not a lookup table. Given a random variable that takes on values in <span class="math">\([0, 1]\)</span>, we do not and cannot define <span class="math">\(\Pr(X = 0.01)\)</span>, <span class="math">\(\Pr(X = 0.001)\)</span>, <span class="math">\(\Pr(X = 0.0001)\)</span>, etc.</li>
<li>Instead, we define a function that tells us the probability of observing a value within a certain <em>range</em>, i.e. <span class="math">\(\Pr(0.01 &lt; X &lt; .4)\)</span>.</li>
<li>This is the probability density function, where <span class="math">\(\Pr(0 \leq X \leq 1) = 1\)</span>.</li>
</ul>
</li>
</ul>
<h2>Entropy</h2>
<p>Entropy quantifies the number of ways we can reach a given outcome. Imagine 8 friends are splitting into 2 taxis en route to a Broadway show. Consider the following two scenarios:</p>
<ul>
<li><em>Four friends climb into each taxi.</em> We could accomplish this with the following assignments:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># fill the first, then the second</span>
<span class="n">assignment_1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># alternate assignments</span>
<span class="n">assignment_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># alternate assignments in batches of two</span>
<span class="n">assignment_3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># etc.</span>
</code></pre></div>
<ul>
<li><em>All friends climb into the first taxi.</em> There is only one possible assignment.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">assignment_1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div>
<p>(In this case, the Broadway show is probably in <a href="http://willtravellife.com/2013/04/how-does-a-west-african-bush-taxi-work/">West Africa</a> or a similar part of the world.)</p>
<p>Since there are more ways to reach the first outcome than there are the second, the first outcome has a higher entropy.</p>
<h3>More explicitly</h3>
<p>We compute entropy for probability distributions. This computation is given as:</p>
<div class="math">$$
H(p) = -\sum\limits_{i=1}^{n} p_i \log{p_i}
$$</div>
<p>where:</p>
<ul>
<li>There are <span class="math">\(n\)</span> distinct events.</li>
<li>Each event <span class="math">\(i\)</span> has probability <span class="math">\(p_i\)</span>.</li>
</ul>
<p>Entropy is the <em>weighted-average log probability</em> over possible events—this much reads directly from the equation—which measures the <em>uncertainty inherent in their probability distribution.</em> The higher the entropy, the less certain we are about the value we're going to get.</p>
<p>Let's calculate the entropy of our distribution above.</p>
<div class="highlight"><pre><span></span><code><span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'rain'</span><span class="p">:</span> <span class="mf">.14</span><span class="p">,</span> <span class="s1">'snow'</span><span class="p">:</span> <span class="mf">.37</span><span class="p">,</span> <span class="s1">'sleet'</span><span class="p">:</span> <span class="mf">.03</span><span class="p">,</span> <span class="s1">'hail'</span><span class="p">:</span> <span class="mf">.46</span><span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span><span class="n">prob_dist</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="nb">sum</span><span class="p">([</span> <span class="n">p</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">prob_dist</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="p">])</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">entropy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="mf">1.1055291211185652</span>
</code></pre></div>
<p>For comparison, let's assume two more distributions and calculate their respective entropies.</p>
<div class="highlight"><pre><span></span><code><span class="n">p_2</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'rain'</span><span class="p">:</span> <span class="mf">.01</span><span class="p">,</span> <span class="s1">'snow'</span><span class="p">:</span> <span class="mf">.37</span><span class="p">,</span> <span class="s1">'sleet'</span><span class="p">:</span> <span class="mf">.03</span><span class="p">,</span> <span class="s1">'hail'</span><span class="p">:</span> <span class="mf">.59</span><span class="p">}</span>

<span class="n">p_3</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'rain'</span><span class="p">:</span> <span class="mf">.01</span><span class="p">,</span> <span class="s1">'snow'</span><span class="p">:</span> <span class="mf">.01</span><span class="p">,</span> <span class="s1">'sleet'</span><span class="p">:</span> <span class="mf">.03</span><span class="p">,</span> <span class="s1">'hail'</span><span class="p">:</span> <span class="mf">.95</span><span class="p">}</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">entropy</span><span class="p">(</span><span class="n">p_2</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="mf">0.8304250977453105</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">entropy</span><span class="p">(</span><span class="n">p_3</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="mf">0.2460287703075343</span>
</code></pre></div>
<p>In the first distribution, we are least certain as to what tomorrow's weather will bring. As such, this has the highest entropy. In the third distribution, we are almost certain it's going to hail. As such, this has the lowest entropy.</p>
<p>Finally, it is a probability distribution that dictates the different taxi assignments just above. A distribution for a random variable that has many possible outcomes has a higher entropy than a distribution that gives only one.</p>
<p>Now, let's dive into the pool. We'll start at the bottom and work our way back to the top.</p>
<h1>Response variable</h1>
<p>Roughly speaking, each model looks as follows. It is a diamond that receives an input and produces an output.</p>
<p><img alt="simple input/output model" class="img-responsive" src="https://willwolf.io/images/simple_input_output_model.png"/></p>
<p>The models differ in the type of response variable they predict, i.e. the <span class="math">\(y\)</span>.</p>
<ul>
<li>Linear regression predicts a continuous-valued real number. Let's call it <code>temperature</code>.</li>
<li>Logistic regression predicts a binary label. Let's call it <code>cat or dog</code>.</li>
<li>Softmax regression predicts a multi-class label. Let's call it <code>red or green or blue</code>.</li>
</ul>
<p>In each model, the response variable can take on a bunch of different values. In other words, they are <em>random variables.</em> What probability distribution is associated with each?</p>
<p>Unfortunately, we don't know. All we do know, in fact, is the following:</p>
<ul>
<li><code>temperature</code> has an underlying true mean <span class="math">\(\mu \in (-\infty, \infty)\)</span> and variance <span class="math">\(\sigma^2 \in (0, \infty)\)</span>.</li>
<li><code>cat or dog</code> takes on the value <code>cat</code> or <code>dog</code>. The likelihood of observing each outcome does not change over time, in the same way that <span class="math">\(\Pr(\text{heads})\)</span> for a fair coin is always <span class="math">\(0.5\)</span>.</li>
<li><code>red or green or blue</code> takes on the value <code>red</code> or <code>green</code> or <code>blue</code>. The likelihood of observing each outcome does not change over time, in the same way that the probability of rolling a given number on a fair die is always <span class="math">\(\frac{1}{6}\)</span>.</li>
</ul>
<p>For clarity, each one of these assumptions is utterly banal. Nonetheless, <em>can we use them nonetheless to select probability distributions for our random variables?</em></p>
<h2>Maximum entropy distributions</h2>
<p>Consider another continuous-valued random variable: "Uber's yearly profit." Like <code>temperature</code>, it also has an underlying true mean <span class="math">\(\mu \in (-\infty, \infty)\)</span> and variance <span class="math">\(\sigma^2 \in (0, \infty)\)</span>. Trivially, the respective means and variances will be different. Assume we observe 10 (fictional) values of each that look as follows:</p>
<table class="table-hover table-striped table">
<thead>
<tr>
<th>uber</th>
<th>temperature</th>
</tr>
</thead>
<tbody>
<tr>
<td>-100</td>
<td>-50</td>
</tr>
<tr>
<td>-80</td>
<td>5</td>
</tr>
<tr>
<td>-20</td>
<td>56</td>
</tr>
<tr>
<td>5</td>
<td>65</td>
</tr>
<tr>
<td>15</td>
<td>62</td>
</tr>
<tr>
<td>-10</td>
<td>63</td>
</tr>
<tr>
<td>22</td>
<td>60</td>
</tr>
<tr>
<td>12</td>
<td>78</td>
</tr>
<tr>
<td>70</td>
<td>100</td>
</tr>
<tr>
<td>100</td>
<td>-43</td>
</tr>
</tbody>
</table>
<p>Plotting, we get:</p>
<p><img alt="temperature random variable" class="img-responsive" src="https://willwolf.io/figures/temperature_random_variable.png"/>
<img alt="uber random variable" class="img-responsive" src="https://willwolf.io/figures/uber_random_variable.png"/></p>
<p>We are not given the true underlying probability distribution associated with each random variable—not its general "shape," nor the parameters that control this shape. We will <em>never</em> be given these things, in fact: the point of statistics is to infer what they are.</p>
<p>To make an initial choice we keep two things in mind:</p>
<ul>
<li><em>We'd like to be conservative</em>. We've only seen ten values of "Uber's yearly profit;" we don't want to discount the fact that the next twenty could fall into <span class="math">\([-60, -50]\)</span> just because they haven't yet been observed.</li>
<li><em>We need to choose the same probability distribution "shape" for both random variables, as we've made identical assumptions for each</em>.</li>
</ul>
<p>As such, we'd like the most conservative distribution that obeys the "utterly banal" constraints stated above. This is the <a href="https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution"><em>maximum entropy distribution</em></a>.</p>
<p>For <code>temperature</code>, the maximum entropy distribution is the <a href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian distribution</a>. Its probability density function is given as:</p>
<div class="math">$$
P(y\vert \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\frac{(y - \mu)^2}{2\sigma^2}\bigg)}
$$</div>
<p>For <code>cat or dog</code>, it is the <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>. Its probability mass function  (for a single observation) is given as:</p>
<div class="math">$$
P(\text{outcome}) =
\begin{cases}
1 - \phi &amp; \text{outcome = cat}\\
\phi &amp; \text{outcome = dog}\\
\end{cases}
$$</div>
<p>(I've written the probability of the positive event as <span class="math">\(\phi\)</span>, e.g. <span class="math">\(\phi = .5\)</span> for a fair coin.)</p>
<p>For <code>red or green or blue</code>, it is the <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>. Its probability mass function (for a single observation) is given as:</p>
<div class="math">$$
P(\text{outcome}) =
\begin{cases}
\phi_{\text{red}} &amp; \text{outcome = red}\\
\phi_{\text{green}} &amp; \text{outcome = green}\\
1 - \phi_{\text{red}} - \phi_{\text{green}} &amp; \text{outcome = blue}\\
\end{cases}
$$</div>
<p>While it may seem like we've "waved our hands" over the connection between the stated equality constraints for the response variable of each model and the respective distributions we've selected, it is <a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">Lagrange multipliers</a> that succinctly and algebraically bridge this gap. This <a href="https://www.dsprelated.com/freebooks/sasp/Maximum_Entropy_Property_Gaussian.html">post</a> gives a terrific example of this derivation. I've chosen to omit it as I did not feel it would contribute to the clarity nor direction of this post.</p>
<p>Finally, while we do assume that a Gaussian dictates the true distribution of values of both "Uber's yearly profit" and <code>temperature</code>, it is, trivially, a different Gaussian for each. This is because each random variable has its own true underlying mean and variance. These values make the respective Gaussians taller or wider—shifted left or shifted right.</p>
<h1>Functional form</h1>
<p>Our three protagonists generate predictions via distinct functions: the <a href="https://en.wikipedia.org/wiki/Identity_function">identity function</a> (i.e. a no-op), the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a> and the <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax function</a>, respectively. The Keras output layers make this clear:</p>
<div class="highlight"><pre><span></span><code><span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></div>
<p>In this section, I'd like to:</p>
<ul>
<li>Show how each of the Gaussian, binomial and multinomial distributions can be reduced to the same functional form.</li>
<li>Show how this common functional form allows us to naturally derive the output functions for our three protagonist models.</li>
</ul>
<h2>Exponential family distributions</h2>
<blockquote>
<p>In probability and statistics, an <a href="https://en.wikipedia.org/wiki/Exponential_family">"exponential family"</a> is a set of probability distributions of a certain form, specified below. This special form is chosen for mathematical convenience, on account of some useful algebraic properties, as well as for generality, as exponential families are in a sense very natural sets of distributions to consider.</p>
</blockquote>
<p>— Wikipedia</p>
<p>I don't relish quoting this paragraph—and especially one so deliriously ambiguous. This said, the reality is that exponential functions provide, at a minimum, a unifying framework for deriving the canonical activation and loss functions we've come to know and love. To move forward, we simply have to cede that the "mathematical conveniences, on account of some useful algebraic properties, etc." that motivate this "certain form" are not totally heinous nor misguided.</p>
<p>A distribution belongs to the exponential family if it can be written in the following form:</p>
<div class="math">$$
P(y; \eta) = b(y)\exp(\eta^T T(y) - a(\eta))
$$</div>
<p>where:</p>
<ul>
<li><span class="math">\(\eta\)</span> is the <em>canonical parameter</em> of the distribution. (We will hereby work with the single-canonical-parameter exponential family form.)</li>
<li><span class="math">\(T(y)\)</span> is the <em>sufficient statistic</em>. It is often the case that <span class="math">\(T(y) = y\)</span>.</li>
<li><span class="math">\(a(\eta)\)</span> is the <em>log partition function</em>, which normalizes the distribution. (A more in-depth discussion of this normalizing constant can be found in a previous post of mine: <a href="https://willwolf.io/2017/04/19/deriving-the-softmax-from-first-principles/">Deriving the Softmax from First Principles</a>.)</li>
</ul>
<p>"A fixed choice of <span class="math">\(T\)</span>, <span class="math">\(a\)</span> and <span class="math">\(b\)</span> defines a family (or set) of distributions that is parameterized by <span class="math">\(\eta\)</span>; as we vary <span class="math">\(\eta\)</span>, we then get different distributions within this family."<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> This simply means that a coin with <span class="math">\(\Pr(\text{heads}) = .6\)</span> gives a different distribution over outcomes than one with <span class="math">\(\Pr(\text{heads}) = .7\)</span>. Easy.</p>
<h3>Gaussian distribution</h3>
<p>Since we're working with the single-parameter form, we'll assume that <span class="math">\(\sigma^2\)</span> is known and equals <span class="math">\(1\)</span>.</p>
<div class="math">$$
\begin{align*}
P(y\vert \mu, \sigma^2)
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\frac{(y - \mu)^2}{2\sigma^2}\bigg)}\\
&amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{(y - \mu)^2}{2}\bigg)}\\
&amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}(y^2 - 2\mu y + \mu^2)\bigg)}\\
&amp;= \frac{1}{\sqrt{2\pi}}\exp{\bigg(-\frac{1}{2}y^2\bigg)} \cdot \exp{\bigg(\mu y - \frac{1}{2}\mu^2\bigg)}\\
\end{align*}
$$</div>
<p>where:</p>
<ul>
<li><span class="math">\(\eta = \mu\)</span></li>
<li><span class="math">\(T(y) = y\)</span></li>
<li><span class="math">\(a(\eta) = \frac{1}{2}\mu^2\)</span></li>
<li><span class="math">\(b(y) = \frac{1}{\sqrt{2\pi}}\exp{(-\frac{1}{2}y^2)}\)</span></li>
</ul>
<p>Finally, we'll express <span class="math">\(a(\eta)\)</span> in terms of <span class="math">\(\eta\)</span> itself:</p>
<div class="math">$$
\begin{align*}
a(\eta)
&amp;= \frac{1}{2}\mu^2\\
&amp;= \frac{1}{2}\eta^2
\end{align*}
$$</div>
<h3>Binomial distribution</h3>
<p>We previously defined the binomial distribution (for a single observation) in a crude, piecewise form. We'll now define it in a more compact form which will make it easier to show that it is a member of the exponential family. Again, <span class="math">\(\phi\)</span> gives the probability of observing the true class, i.e. <span class="math">\(\Pr(\text{cat}) = .7 \implies \phi = .3\)</span>.</p>
<div class="math">$$
\begin{align*}
P(y\vert \phi)
&amp;= \phi^y(1-\phi)^{1-y}\\
&amp;= \exp\bigg(\log\bigg(\phi^y(1-\phi)^{1-y}\bigg)\bigg)\\
&amp;= \exp\bigg(y\log{\phi} + \log(1-\phi) - y\log(1-\phi)\bigg)\\
&amp;= \exp\bigg(\log\bigg(\frac{\phi}{1-\phi}\bigg)y + \log(1-\phi)\bigg) \\
\end{align*}
$$</div>
<p>where:</p>
<ul>
<li><span class="math">\(\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg)\)</span></li>
<li><span class="math">\(T(y) = y\)</span></li>
<li><span class="math">\(a(\eta) = -\log(1-\phi)\)</span></li>
<li><span class="math">\(b(y) = 1\)</span></li>
</ul>
<p>Finally, we'll express <span class="math">\(a(\eta)\)</span> in terms of <span class="math">\(\eta\)</span>, i.e. the parameter that this distribution accepts:</p>
<div class="math">$$
\eta = \log\bigg(\frac{\phi}{1-\phi}\bigg) \implies \phi = \frac{1}{1 + e^{-\eta}}
$$</div>
<div class="math">$$
\begin{align*}
a(\eta)
&amp;= -\log(1-\phi)\\
&amp;= -\log\bigg(1-\frac{1}{1 + e^{-\eta}}\bigg)\\
&amp;= -\log\bigg(\frac{1}{1 + e^{\eta}}\bigg)\\
&amp;= \log(1 + e^{\eta})\\
\end{align*}
$$</div>
<p>You will recognize our expression for <span class="math">\(\phi\)</span>—the probability of observing the true class—as the sigmoid function.</p>
<h3>Multinomial distribution</h3>
<p>Like the binomial distribution, we'll first rewrite the multinomial (for a single observation) in a more compact form. <span class="math">\(\pi\)</span> gives a vector of class probabilities for the <span class="math">\(K\)</span> classes; <span class="math">\(k\)</span> denotes one of these classes.</p>
<div class="math">$$
P(y\vert \pi) = \prod\limits_{k=1}^{K}\pi_k^{y_k}
$$</div>
<p>This is almost pedantic: it says that <span class="math">\(\Pr(y=k)\)</span> equals the probability of observing class <span class="math">\(k\)</span>. For example, given</p>
<div class="highlight"><pre><span></span><code><span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'rain'</span><span class="p">:</span> <span class="mf">.14</span><span class="p">,</span> <span class="s1">'snow'</span><span class="p">:</span> <span class="mf">.37</span><span class="p">,</span> <span class="s1">'sleet'</span><span class="p">:</span> <span class="mf">.03</span><span class="p">,</span> <span class="s1">'hail'</span><span class="p">:</span> <span class="mf">.46</span><span class="p">}</span>
</code></pre></div>
<p>we would compute:</p>
<div class="math">$$
\begin{align*}
\Pr(y = \text{snow} = [0, 1, 0, 0])
&amp;= (.14^0 * .37^1 * .03^0 * .46^0)\\
&amp;= .37\\
\end{align*}
$$</div>
<p>Expanding into the exponential family form gives:</p>
<div class="math">$$
\begin{align*}
P(y\vert \pi)
&amp;= \prod\limits_{k=1}^{K}\pi_k^{y_k}\\
&amp;= \exp\bigg(\sum\limits_{k=1}^{K}y_k\log{\pi_k}\bigg)\\
&amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} + \bigg(1 - \sum\limits_{k=1}^{K-1}y_k\bigg)\log\bigg(1 - \sum\limits_{k=1}^{K-1}\pi_k\bigg)\bigg)\\
&amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}y_k\log{\pi_k} - \bigg(\sum\limits_{k=1}^{K-1}y_k\bigg) \log(\pi_K) + \log(\pi_K)), \quad \text{where}\ \pi_K = 1 - \sum\limits_{k=1}^{K-1}\pi_k\\
&amp;= \exp\bigg(\sum\limits_{k=1}^{K-1}\log\bigg(\frac{\pi_k}{\pi_K}\bigg) y_k + \log(\pi_K)\bigg)
\end{align*}
$$</div>
<p>where:</p>
<ul>
<li><span class="math">\(\eta_k = \log\bigg(\frac{\pi_k}{\pi_K}\bigg)\)</span></li>
<li><span class="math">\(T(y) = y\)</span></li>
<li><span class="math">\(a(\eta) = -\log(\pi_K)\)</span></li>
<li><span class="math">\(b(y) = 1\)</span></li>
</ul>
<p>Finally, we'll express <span class="math">\(a(\eta)\)</span> in terms of <span class="math">\(\eta\)</span>, i.e. the parameter that this distribution accepts:</p>
<div class="math">$$
\begin{align*}
\eta_k
  &amp;= \log\bigg(\frac{\pi_k}{\pi_K}\bigg) \implies\\
\frac{\pi_k}{\pi_K}
  &amp;= e^{\eta_k} \implies\\
\sum\limits_{k=1}^K \frac{\pi_k}{\pi_K}
  &amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\
\frac{1}{\pi_K}\sum\limits_{k=1}^K \pi_k
  &amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\
\frac{1}{\pi_K} \cdot 1
  &amp;= \sum\limits_{k=1}^K e^{\eta_k} \implies\\
\pi_K
  &amp;= \frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}
\end{align*}
$$</div>
<p>Plugging back into the second line we get:</p>
<div class="math">$$
\begin{align*}
\frac{\pi_k}{\frac{1}{\sum\limits_{k=1}^K e^{\eta_k}}}
  &amp;= e^{\eta_k}\ \implies\\
\pi_k
  &amp;= \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}
\end{align*}
$$</div>
<p>This you will recognize as the softmax function. (For a probabilistically-motivated derivation, please see a previous <a href="https://willwolf.io/2017/04/19/deriving-the-softmax-from-first-principles/">post</a>.)</p>
<p>Finally:</p>
<div class="math">$$
\begin{align*}
\frac{\pi_k}{\pi_K}
  &amp;= e^{\eta_k} \implies\\
\frac{\pi_K}{\pi_K}
  &amp;= e^{\eta_K} \implies\\
\eta_K &amp;= 0\\
\end{align*}
$$</div>
<div class="math">$$
\begin{align*}
a(\eta)
&amp;= -\log(\pi_K)\\
&amp;= \log(\pi_K^{-1})\\
&amp;= \log\Bigg(\frac{\sum\limits_{k=1}^K e^{\eta_k}}{e^{\eta_K}}\Bigg)\\
&amp;= \log\Bigg(\sum\limits_{k=1}^K e^{\eta_k}\Bigg)\\
\end{align*}
$$</div>
<h2>Generalized linear models</h2>
<p>Each protagonist model outputs a response variable that is distributed according to some (exponential family) distribution. However, the <em>canonical parameter</em> of this distribution, i.e. the thing we pass in, will <em>vary per observation</em>.</p>
<p>Consider the logistic regression model that's predicting <code>cat or dog</code>. If we input a picture of a cat, we'll output "cat" according to the stated distribution.</p>
<div class="math">$$
P(\text{outcome}) =
\begin{cases}
1 - \phi &amp; \text{outcome = cat}\\
\phi &amp; \text{outcome = dog}\\
\end{cases}
$$</div>
<p>If we input a picture of a dog, we'll output "dog" according the same distribution.</p>
<div class="math">$$
P(\text{outcome}) =
\begin{cases}
1 - \phi &amp; \text{outcome = cat}\\
\phi &amp; \text{outcome = dog}\\
\end{cases}
$$</div>
<p>Trivially, <em>the <span class="math">\(\phi\)</span> value must be different in each case.</em> In the former, <span class="math">\(\phi\)</span> should be small, such that we output "cat" with probability <span class="math">\(1 - \phi \approx 1\)</span>. In the latter, <span class="math">\(\phi\)</span> should be large, such that we output "dog" with probability <span class="math">\(\phi \approx 1\)</span>.</p>
<p>So, what dictates the following?</p>
<ul>
<li><span class="math">\(\mu_i\)</span> in the case of linear regression, in which <span class="math">\(y_i \sim \mathcal{N}(\mu_i, \sigma^2)\)</span></li>
<li><span class="math">\(\phi_i\)</span> in the case of logistic regression, in which <span class="math">\(y_i \sim \text{Binomial}(\phi_i, 1)\)</span></li>
<li><span class="math">\(\pi_i\)</span> in the case of softmax regression, in which <span class="math">\(y_i \sim \text{Multinomial}(\pi_i, 1)\)</span></li>
</ul>
<p>Here, I've introduced the subscript <span class="math">\(i\)</span>. This makes explicit the <code>cat or dog</code> dynamic from above: each input to a given model will result in its <em>own</em> canonical parameter being passed to the distribution on the response variable. (That logistic regression better make <span class="math">\(\phi_i \approx 0\)</span> when looking at a picture of a cat!)</p>
<p>Finally, how do we go from a 10-feature input <span class="math">\(x\)</span> to this canonical parameter? We take a linear combination:</p>
<div class="math">$$
\eta = \theta^Tx
$$</div>
<h3>Linear regression</h3>
<p><span class="math">\(\eta = \theta^Tx = \mu_i\)</span>. This is what we need for the normal distribution.</p>
<p><em><strong>&gt; The identity function (i.e a no-op) gives us the mean of the response variable. This mean is required by the normal distribution, which dictates the outcomes of the continuous-valued target <span class="math">\(y\)</span>.</strong></em></p>
<h3>Logistic regression</h3>
<p><span class="math">\(\eta = \theta^Tx = \log\bigg(\frac{\phi_i}{1-\phi_i}\bigg)\)</span>. To solve for <span class="math">\(\phi_i\)</span>, we solve for <span class="math">\(\phi_i\)</span>.</p>
<p>As you'll remember we did this above: <span class="math">\(\phi_i = \frac{1}{1 + e^{-\eta}}\)</span>.</p>
<p><em><strong>&gt; The sigmoid function gives us the probability that the response variable takes on the positive class. This probability is required by the binomial distribution, which dictates the outcomes of the binary target <span class="math">\(y\)</span>.</strong></em></p>
<h3>Softmax regression</h3>
<p><span class="math">\(\eta = \theta^Tx = \log\bigg(\frac{\pi_k}{\pi_K}\bigg)\)</span>. To solve for <span class="math">\(\pi_i\)</span>, i.e. the full vector of probabilities for observation <span class="math">\(i\)</span>, we solve for each individual probability <span class="math">\(\pi_{k, i}\)</span> then put them in a list.</p>
<p>We did this above as well: <span class="math">\(\pi_{k, i} = \frac{e^{\eta_k}}{\sum\limits_{k=1}^K e^{\eta_k}}\)</span>. This is the softmax function.</p>
<p><em><strong>&gt; The softmax function gives us the probability that the response variable takes on each of the possible classes. This probability mass function is required by the multinomial distribution, which dictates the outcomes of the multi-class target <span class="math">\(y\)</span>.</strong></em></p>
<p>Finally, why a linear model, i.e. why <span class="math">\(\eta = \theta^Tx\)</span>?</p>
<p>Andrew Ng calls it a "design choice."<sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">1</a></sup> I've motivated this formulation a bit in the <a href="https://willwolf.io/2017/04/19/deriving-the-softmax-from-first-principles/">softmax post</a>. mathematicalmonk<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup> would probably have a more principled explanation than us both. For now, we'll make do with the following:</p>
<ul>
<li>A linear combination is perhaps the simplest way to consider the impact of each feature on the canonical parameter.</li>
<li>A linear combination commands that either <span class="math">\(x\)</span>, or a <em>function of <span class="math">\(x\)</span></em>, vary linearly with <span class="math">\(\eta\)</span>. As such, we could write our model as <span class="math">\(\eta = \theta^T\Phi(x)\)</span>, where <span class="math">\(\Phi\)</span> applies some complex transformation to our features. This makes the "simplicity" of the linear combination less simple.</li>
</ul>
<h1>Loss function</h1>
<p>We've now discussed how each response variable is generated, and how we compute the parameters for those distributions on a per-observation basis. Now, how do we quantify how good these parameters are?</p>
<p>To get us started, let's go back to predicting <code>cat or dog</code>. If we input a picture of a cat, we should compute <span class="math">\(\phi \approx 0\)</span> given our binomial distribution.</p>
<div class="math">$$
P(\text{outcome}) =
\begin{cases}
1 - \phi &amp; \text{outcome = cat}\\
\phi &amp; \text{outcome = dog}\\
\end{cases}
$$</div>
<p>A perfect computation gives <span class="math">\(\phi = 0\)</span>. The loss function quantifies how close we got.</p>
<h2>Maximum likelihood estimation</h2>
<p>Each of our three random variables receives a parameter—<span class="math">\(\mu, \phi\)</span> and <span class="math">\(\pi\)</span> respectively. We then pass in a <span class="math">\(y\)</span>: for discrete-valued random variables, the associated probability mass function tells us the probability of observing this value; for continuous-valued random variables, the associated probability density function tells us the density of the probability space around this value (a number proportional to the probability).</p>
<p>If we instead <em>fix</em> <span class="math">\(y\)</span> and pass in varying <em>parameter values</em>, this same function becomes a <em>likelihood function</em>. It will tell us the likelihood of a given parameter having produced the now-fixed <span class="math">\(y\)</span>.</p>
<p>If this is not clear, consider the following example:</p>
<blockquote>
<p>A Moroccan walks into a bar. He's wearing a football jersey that's missing a sleeve. He has a black eye, and blood on his jeans. How did he most likely spend his day?</p>
<ol>
<li>At home, reading a book.</li>
<li>Training for a bicycle race.</li>
<li>At the soccer game drinking beers with his friends—all of whom are MMA fighters that despise the other team.</li>
</ol>
</blockquote>
<p>We'd like to pick the parameter that most likely gave rise to our data. This is the <em>maximum likelihood estimate</em>. Mathematically, we define it as:</p>
<div class="math">$$
\underset{\text{parameter}}{\arg\max}\ P(y\vert \text{parameter})
$$</div>
<p>As we've now seen (ad nauseum), <span class="math">\(y\)</span> depends on the parameter its generating random variable receives. Additionally, this parameter—<span class="math">\(\mu, \phi\)</span> or <span class="math">\(\pi\)</span>—is defined in terms of <span class="math">\(\eta\)</span>. Further, <span class="math">\(\eta = \theta^T x\)</span>. As such, <span class="math">\(y\)</span> is a function of <span class="math">\(\theta\)</span> and the observed data <span class="math">\(x\)</span>. This is perhaps <em>the</em> elementary truism of machine learning—you've known this since Day 1.</p>
<p>Since our observed data are fixed, <span class="math">\(\theta\)</span> is the only thing that we can vary. Let's rewrite our argmax in these terms:</p>
<div class="math">$$
\underset{\theta}{\arg\max}\ P(y\vert x; \theta)
$$</div>
<p>Finally, this expression gives the argmax over a single data point, i.e. training observation, <span class="math">\((x^{(i)}, y^{(i)})\)</span>. To give the likelihood over all observations (assuming they are independent of one another, i.e. the outcome of the first observation does not impact that of the third), we take the product.</p>
<div class="math">$$
\underset{\theta}{\arg\max} \prod\limits_{i=1}^{m}P(y^{(i)}\vert x^{(i)}; \theta)
$$</div>
<p>The product of numbers in <span class="math">\([0, 1]\)</span> gets very small, very quickly. Let's maximize the log-likelihood instead so we can work with sums.</p>
<h3>Linear regression</h3>
<p>Maximize the log-likelihood of the Gaussian distribution. Remember, <span class="math">\(x\)</span> and <span class="math">\(\theta\)</span> assemble to give <span class="math">\(\mu\)</span>, where <span class="math">\(\theta^Tx = \mu\)</span>.</p>
<div class="math">$$
\begin{align*}
\log{P(y\vert x; \theta)}
&amp;= \log{\prod\limits_{i=1}^{m}P(y^{(i)}\vert x^{(i)}; \theta)}\\
&amp;= \sum\limits_{i=1}^{m}\log{P(y^{(i)}\vert x^{(i)}; \theta)}\\
&amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}}\\
&amp;= \sum\limits_{i=1}^{m}\log{\frac{1}{\sqrt{2\pi}\sigma}} + \sum\limits_{i=1}^{m}\log\Bigg(\exp{\bigg(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}\bigg)}\Bigg)\\
&amp;= m\log{\frac{1}{\sqrt{2\pi}\sigma}} - \frac{1}{2\sigma^2}\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\
&amp;= C_1 - C_2\sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2\\
\end{align*}
$$</div>
<p>Maximizing the log-likelihood of our data with respect to <span class="math">\(\theta\)</span> is equivalent to maximizing the negative mean squared error between the observed <span class="math">\(y\)</span> and our prediction thereof.</p>
<p>Notwithstanding, most optimization routines <em>minimize</em>. So, for practical purposes, we go the other way.</p>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> is equivalent to minimizing the mean squared error between the observed <span class="math">\(y\)</span> and our prediction thereof.</strong></em></p>
<h3>Logistic regression</h3>
<p>Same thing.</p>
<p>Negative log-likelihood:</p>
<div class="math">$$
\begin{align*}
-\log{P(y\vert x; \theta)}
&amp;= -\log{\prod\limits_{i = 1}^m(\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}}\\
&amp;= -\sum\limits_{i = 1}^m\log{\bigg((\phi^{(i)})^{y^{(i)}}(1 - \phi^{(i)})^{1 - y^{(i)}}\bigg)}\\
&amp;= -\sum\limits_{i = 1}^my^{(i)}\log{(\phi^{(i)})} + (1 - y^{(i)})\log{(1 - \phi^{(i)})}\\
\end{align*}
$$</div>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> is equivalent to minimizing the binary cross-entropy (i.e. binary log loss) between the observed <span class="math">\(y\)</span> and our prediction of the probability thereof.</strong></em></p>
<h3>Multinomial distribution</h3>
<p>Negative log-likelihood:</p>
<div class="math">$$
\begin{align*}
-\log{P(y\vert x; \theta)}
&amp;= -\log\prod\limits_{i=1}^{m}\prod\limits_{k=1}^{K}\pi_k^{y_k}\\
&amp;= -\sum\limits_{i=1}^{m}\sum\limits_{k=1}^{K}y_k\log\pi_k\\
\end{align*}
$$</div>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> is equivalent to minimizing the categorical cross-entropy (i.e. multi-class log loss) between the observed <span class="math">\(y\)</span> and our prediction of the probability distribution thereof.</strong></em></p>
<h1>Maximum a posteriori estimation</h1>
<p>When estimating <span class="math">\(\theta\)</span> via the MLE, we put no constraints on the permissible values thereof. More explicitly, we allow <span class="math">\(\theta\)</span> to be <em>equally likely to assume any real number</em>—be it <span class="math">\(0\)</span>, or <span class="math">\(10\)</span>, or <span class="math">\(-20\)</span>, or <span class="math">\(2.37 \times 10^{36}\)</span>.</p>
<p>In practice, this assumption is both unrealistic and impractical: typically, we do wish to constrain <span class="math">\(\theta\)</span> (our weights) to a non-infinite range of values. We do this by putting a <em>prior</em> on <span class="math">\(\theta\)</span>. Whereas the MLE computes <span class="math">\(\underset{\theta}{\arg\max}\ P(y\vert x; \theta)\)</span>, the maximum a posteriori estimate, or MAP, computes <span class="math">\(\underset{\theta}{\arg\max}\ P(y\vert x; \theta)P(\theta)\)</span>.</p>
<p>As before, we start by taking the log. Our joint likelihood with prior now reads:</p>
<div class="math">$$
\begin{align*}
\theta_{MAP}
&amp;= \underset{\theta}{\arg\max}\ \log \prod\limits_{i=1}^{m} P(y^{(i)}\vert x^{(i)}; \theta)P(\theta)\\
&amp;= \underset{\theta}{\arg\max}\ \sum\limits_{i=1}^{m} \log{P(y^{(i)}\vert x^{(i)}; \theta)} + \log{P(\theta)}\\
\end{align*}
$$</div>
<p>We dealt with the left term in the previous section. Now, we'll simply tack on the log-prior to the respective log-likelihoods.</p>
<p>As every element of <span class="math">\(\theta\)</span> is a continuous-valued real number, let's assign it a Gaussian distribution with mean 0 and variance <span class="math">\(V\)</span>.</p>
<div class="math">$$
\theta \sim \mathcal{N}(0, V)
$$</div>
<div class="math">$$
\begin{align*}
\log{P(\theta\vert 0, V)}
&amp;= \log\Bigg(\frac{1}{\sqrt{2\pi}V}\exp{\bigg(-\frac{(\theta - 0)^2}{2V^2}\bigg)}\Bigg)\\
&amp;= \log{C_1} -\frac{\theta^2}{2V^2}\\
&amp;= \log{C_1} - C_2\theta^2\\
\end{align*}
$$</div>
<p>Our goal is to maximize this term plus the log-likelihood—or equivalently, minimize their opposite—with respect to <span class="math">\(\theta\)</span>. For a final step, let's discard the parts that don't include <span class="math">\(\theta\)</span> itself.</p>
<div class="math">$$
\begin{align*}
\log{C_1} - C_2\theta^2
&amp;\propto - C_2\theta^2\\
&amp;\propto C\Vert \theta\Vert_{2}^{2}\\
\end{align*}
$$</div>
<p>This is L2 regularization. Furthermore, placing different prior distributions on <span class="math">\(\theta\)</span> yields different regularization terms; notably, a <a href="https://en.wikipedia.org/wiki/Laplace_distribution">Laplace prior</a> gives the L1.</p>
<h2>Linear regression</h2>
<div class="math">$$
\underset{\theta}{\arg\min} \sum\limits_{i=1}^{m}(y^{(i)} - \theta^Tx^{(i)})^2 + C\Vert \theta\Vert_{2}^{2}
$$</div>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> given a Gaussian prior on <span class="math">\(\theta\)</span> is equivalent to minimizing the mean squared error between the observed <span class="math">\(y\)</span> and our prediction thereof, plus the sum of the squares of the elements of <span class="math">\(\theta\)</span> itself.</strong></em></p>
<h2>Logistic regression</h2>
<div class="math">$$
\underset{\theta}{\arg\min}
-\sum\limits_{i = 1}^my^{(i)}\log{(\phi^{(i)})} + (1 - y^{(i)})\log{(1 - \phi^{(i)})} + C\Vert \theta\Vert_{2}^{2}
$$</div>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> given a Gaussian prior on <span class="math">\(\theta\)</span> is equivalent to minimizing the binary cross-entropy (i.e. binary log loss) between the observed <span class="math">\(y\)</span> and our prediction of the probability thereof, plus the sum of the squares of the elements of <span class="math">\(\theta\)</span> itself.</strong></em></p>
<h2>Softmax regression</h2>
<div class="math">$$
-\sum\limits_{i=1}^{m}\sum\limits_{k=1}^{K}y_k\log\pi_k + C\Vert \theta\Vert_{2}^{2}
$$</div>
<p><em><strong>&gt; Minimizing the negative log-likelihood of our data with respect to <span class="math">\(\theta\)</span> given a Gaussian prior on <span class="math">\(\theta\)</span> is equivalent to minimizing the categorical cross-entropy (i.e. multi-class log loss) between the observed <span class="math">\(y\)</span> and our prediction of the probability distribution thereof, plus the sum of the squares of the elements of <span class="math">\(\theta\)</span> itself.</strong></em></p>
<p>Finally, in machine learning, we say that regularizing our weights ensures that "no weight becomes too large," i.e. too "influential" in predicting <span class="math">\(y\)</span>. In statistical terms, we can equivalently say that this term <em>restricts the permissible values of these weights to a given interval.</em> (Furthermore, this interval is dictated by the scaling constant <span class="math">\(C\)</span>, which intrinsically parameterizes the prior distribution itself.* In L2 regularization, this scaling constant gives the variance of the Gaussian.)</p>
<h1>Going fully Bayesian</h1>
<p>The key goal of a predictive model is to compute the following distribution:</p>
<div class="math">$$
P(y\vert x, D) = \int P(y\vert x, D, \theta)P(\theta\vert x, D)d\theta
$$</div>
<p>By term, this reads:</p>
<ul>
<li><span class="math">\(P(y\vert x, D)\)</span>: given historical data <span class="math">\(D = ((x^{(i)}, y^{(i)}), ..., (x^{(m)}, y^{(m)}))\)</span>, i.e. some training data, and a new observation <span class="math">\(x\)</span>, compute the distribution of the possible values of the response <span class="math">\(y\)</span>.<ul>
<li>In machine learning, we typically select a <em>single value</em> from this distribution, i.e. point estimate.</li>
</ul>
</li>
<li><span class="math">\(P(y\vert x, D, \theta)\)</span>: given historical data <span class="math">\(D\)</span>, a new observation <span class="math">\(x\)</span> and <em>any plausible value of <span class="math">\(\theta\)</span></em>, i.e. perhaps not the optimal value, compute <span class="math">\(y\)</span>.<ul>
<li>This is given by the functional form of the model in question, i.e. <span class="math">\(y = \theta^Tx\)</span> in the case of linear regression.</li>
</ul>
</li>
<li><span class="math">\(P(\theta\vert x, D)\)</span>: given historical data <span class="math">\(D\)</span> and a new observation <span class="math">\(x\)</span>, compute the distribution of the values of <span class="math">\(\theta\)</span> that plausibly gave rise to our data.<ul>
<li>The <span class="math">\(x\)</span> plays no part; it's simply there such that the expression under the integral factors correctly.</li>
<li>In machine learning, we typically select the MLE or MAP estimate of that distribution, i.e. a single value, or point estimate.</li>
</ul>
</li>
</ul>
<p>In a perfect world, we'd do the following:</p>
<ul>
<li>Compute the <em>full distribution</em> over <span class="math">\(\theta\)</span>.</li>
<li>With each value in this distribution and a new observation <span class="math">\(x\)</span>, compute <span class="math">\(y\)</span>.<ul>
<li>NB: <span class="math">\(\theta\)</span> is an object which contains all of our weights. In 10-feature linear regression, it will have 10 elements. In a neural network, it could have millions.</li>
</ul>
</li>
<li>We now have a <em>full distribution</em> over the possible values of the response <span class="math">\(y\)</span>.</li>
</ul>
<p><em><strong>&gt; Instead of a point estimate for <span class="math">\(\theta\)</span>, and a point estimate for <span class="math">\(y\)</span> given a new observation <span class="math">\(x\)</span> (which makes use of <span class="math">\(\theta\)</span>), we have distributions for each</strong></em>.</p>
<p>Unfortunately, in complex systems with a non-trivial functional form and number of weights, this computation becomes intractably large. As such, in fully Bayesian modeling, we approximate these distributions. In classic machine learning, we assign them a single value (point estimate). It's a bit lazy, really.</p>
<p><img alt="@betanalpha bayesian tweet" class="img-responsive" src="https://willwolf.io/images/going_fully_bayesian.png"/></p>
<h1>Summary</h1>
<p>I hope this post serves as useful context for the machine learning models we know and love. A deeper understanding of these algorithms offers humility—the knowledge that none of these concepts are particularly new—as well as a vision for how to extend these algorithms in the direction of robustness and increased expressivity.</p>
<p>Thanks so much for reading this far. Now, climb out of the pool, grab a towel and <code>import sklearn</code>.</p>
<p><img alt="drink and towel" class="img-responsive" src="https://www.washingtonian.com/wp-content/uploads/2015/05/Pool520-994x664.jpg"/></p>
<h2>Resources</h2>
<p>I recently gave a talk on this topic at <a href="https://www.facebook.com/groups/265793323822652">Facebook Developer Circle: Casablanca</a>. Voilà the:</p>
<ul>
<li><a href="https://www.slideshare.net/WilliamWolfDataScien/youve-been-doing-statistics-all-along">Slides</a></li>
<li><a href="https://www.facebook.com/aboullaite.mohammed/videos/1959648697600819/">Video</a></li>
</ul>
<div class="footnote">
<hr/>
<ol>
<li id="fn:1">
<p><a href="http://cs229.stanford.edu/materials.html">CS229 Machine Learning Course Materials, Lecture Notes 1</a> <a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">↩</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:2">
<p><a href="https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA">mathematical monk - Machine Learning</a> <a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
</ol>
</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
	<hr>
	<h2>Comments</h2>
<a href="http://twitter.com/share" class="twitter-share-button" data-count="horizontal" data-via="willwolf_">Tweet</a><script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'willwolf';
    var disqus_title = 'Minimizing the Negative Log-Likelihood, in English';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</div> </div>
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="row">
			<div class="col-md-11 col-md-offset-1" id="footer-wrapper">
				<div class="col-md-3">
					<div id="social-links">
						<h4>
							Contact
						</h4>
						<li><a href="mailto:williamabrwolf@gmail.com">Email</a></li>
							<li><a href="http://twitter.com/willwolf_">Twitter</a></li>
							<li><a href="http://linkedin.com/in/williamabrwolf">LinkedIn</a></li>
							<li><a href="http://calendly.com/willwolf">Calendly</a></li>
					</div>
				</div>
				<div class="col-md-3">
					<div id="other-links">
						<h4>
							Links
						</h4>
						<ul>
							<li><a href="https://tinyletter.com/willwolf">Newsletter</a></li>
							<li><a href="http://willtravellife.com">Travel Blog</a></li>
							<li><a href="http://github.com/cavaunpeu">Github</a></li>
							<li><a href="https://github.com/cavaunpeu/willwolf.io-source">Source Code</a></li>
						</ul>
					</div>
				</div>
				<div class="col-md-3">
				  <div id="categories">
				    <h4>
				      Categories
				    </h4>
				    <ul>
				      <li><a href="https://willwolf.io/geopolitics/">geopolitics</li>
				      <li><a href="https://willwolf.io/life/">life</li>
				      <li><a href="https://willwolf.io/machine-learning/">machine-learning</li>
				    </ul>
				  </div>
				</div>
				<div class="col-md-3">
				  <div id="pages">
				    <h4>
				      Pages
				    </h4>
				    <ul>
				      <li><a href="https://willwolf.io/archive/" title="Archive">Archive</a></li>
				      <li><a href="https://willwolf.io/resume.pdf" title="Résumé">Résumé</a></li>
				    </ul>
				  </div>
				</div>
			</div>
		</div>
	</div>
</footer><div class="container">
	<div class="row">
		<div class="col-md-12 text-center center-block aw-bottom">
			<p>&copy; Will Wolf 2020</p>
			<p>Powered by Pelican</p>
		</div>
	</div>
</div><!-- JavaScript -->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-97412095-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>